---
title: "‡∏ö‡∏ó‡∏ó‡∏µ‡πà 11: ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"
description: "‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå AI ‡∏à‡∏£‡∏¥‡∏á 3 ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå ‚Äî Chatbot, RAG Q&A System, ‡πÅ‡∏•‡∏∞ Multi-Agent Research Assistant"
sidebar:
  order: 11
---

import {
  Aside,
  Tabs,
  TabItem,
  Steps,
  Card,
  CardGrid,
} from "@astrojs/starlight/components";

## ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÉ‡∏ô‡∏ö‡∏ó‡∏ô‡∏µ‡πâ

<CardGrid>
  <Card title="ü§ñ Project 1: AI Chatbot" icon="comment">
    ‡∏™‡∏£‡πâ‡∏≤‡∏á Chatbot ‡∏≠‡πÄ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏û‡∏£‡πâ‡∏≠‡∏° memory ‡πÅ‡∏•‡∏∞ streaming
  </Card>
  <Card title="üìö Project 2: PDF Q&A" icon="open-book">
    ‡∏™‡∏£‡πâ‡∏≤‡∏á RAG system ‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ PDF
  </Card>
  <Card title="üî¨ Project 3: Research Agent" icon="magnifier">
    ‡∏™‡∏£‡πâ‡∏≤‡∏á Multi-Agent ‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏Ñ‡∏ß‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
  </Card>
</CardGrid>

---

## Project 1: AI Chatbot ‡∏û‡∏£‡πâ‡∏≠‡∏° Streaming

### ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ

- ‚úÖ Chat Model + Memory
- ‚úÖ Streaming response
- ‚úÖ System prompt customization
- ‚úÖ FastAPI integration

### Full Source Code

‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Python ‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

```python title="chatbot.py"
import asyncio
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory

# ===== Configuration =====
SYSTEM_PROMPT = """‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ "‡∏ô‡πâ‡∏≠‡∏áAI" ‚Äî ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞
üéØ ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å
üí° ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå
üìù ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÇ‡∏Ñ‡πâ‡∏î ‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢
üòä ‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£ ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏à"""

# ===== Setup =====
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7, streaming=True)
store = {}

def get_history(session_id: str):
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

prompt = ChatPromptTemplate.from_messages([
    ("system", SYSTEM_PROMPT),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{input}"),
])

chain = prompt | llm | StrOutputParser()

chatbot = RunnableWithMessageHistory(
    chain, get_history,
    input_messages_key="input",
    history_messages_key="history",
)

# ===== Streaming Chat =====
async def chat_stream(user_message: str, session_id: str = "default"):
    config = {"configurable": {"session_id": session_id}}

    print("ü§ñ ‡∏ô‡πâ‡∏≠‡∏áAI: ", end="", flush=True)
    async for chunk in chatbot.astream(
        {"input": user_message},
        config=config,
    ):
        print(chunk, end="", flush=True)
    print()  # newline

# ===== Main Loop =====
async def main():
    print("=" * 50)
    print("ü§ñ ‡∏ô‡πâ‡∏≠‡∏áAI ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£!")
    print("üí° ‡∏û‡∏¥‡∏°‡∏û‡πå 'quit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å")
    print("=" * 50)

    while True:
        user_input = input("\nüë§ ‡∏Ñ‡∏∏‡∏ì: ")
        if user_input.lower() in ["quit", "exit", "q"]:
            print("üëã ‡∏•‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö! ‡πÅ‡∏•‡πâ‡∏ß‡∏û‡∏ö‡∏Å‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏ô‡∏∞")
            break
        if not user_input.strip():
            continue

        await chat_stream(user_input)

if __name__ == "__main__":
    asyncio.run(main())
```

### ‡πÄ‡∏û‡∏¥‡πà‡∏° FastAPI Endpoint

‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Python ‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

```python title="chatbot_api.py"
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from pydantic import BaseModel

app = FastAPI(title="‡∏ô‡πâ‡∏≠‡∏áAI Chatbot API")

class ChatRequest(BaseModel):
    message: str
    session_id: str = "default"

@app.post("/chat")
async def chat(request: ChatRequest):
    config = {"configurable": {"session_id": request.session_id}}
    result = chatbot.invoke(
        {"input": request.message},
        config=config,
    )
    return {"response": result}

@app.post("/chat/stream")
async def chat_stream_api(request: ChatRequest):
    config = {"configurable": {"session_id": request.session_id}}

    async def generate():
        async for chunk in chatbot.astream(
            {"input": request.message},
            config=config,
        ):
            yield chunk

    return StreamingResponse(generate(), media_type="text/plain")
```

---

## Project 2: PDF Q&A System (RAG)

### ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ

- ‚úÖ Document loading + splitting
- ‚úÖ Vector store (ChromaDB)
- ‚úÖ RAG chain
- ‚úÖ Source citation

### Full Source Code

‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Python ‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

```python title="pdf_qa.py"
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from pathlib import Path

class PDFQASystem:
    """‡∏£‡∏∞‡∏ö‡∏ö‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ PDF"""

    def __init__(self, persist_dir: str = "./chroma_db"):
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        self.persist_dir = persist_dir
        self.vectorstore = None
        self.chain = None

    def load_pdfs(self, pdf_path: str):
        """‡πÇ‡∏´‡∏•‡∏î PDF ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏±‡πâ‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå"""
        path = Path(pdf_path)

        if path.is_file():
            print(f"üìÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î: {path.name}")
            docs = PyPDFLoader(str(path)).load()
        elif path.is_dir():
            print(f"üìÅ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: {path}")
            loader = DirectoryLoader(str(path), glob="**/*.pdf",
                                      loader_cls=PyPDFLoader)
            docs = loader.load()
        else:
            raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö: {pdf_path}")

        print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ {len(docs)} ‡∏´‡∏ô‡πâ‡∏≤")

        # ‡πÅ‡∏ö‡πà‡∏á chunks
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", ".", " "],
        )
        chunks = splitter.split_documents(docs)
        print(f"üì¶ ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô {len(chunks)} chunks")

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á vector store
        self.vectorstore = Chroma.from_documents(
            documents=chunks,
            embedding=self.embeddings,
            persist_directory=self.persist_dir,
        )
        print("‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Store ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢!")

        self._build_chain()

    def load_existing(self):
        """‡πÇ‡∏´‡∏•‡∏î vector store ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß"""
        self.vectorstore = Chroma(
            persist_directory=self.persist_dir,
            embedding_function=self.embeddings,
        )
        self._build_chain()
        print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î Vector Store ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢!")

    def _build_chain(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á RAG chain"""
        retriever = self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 4},
        )

        prompt = ChatPromptTemplate.from_template("""
‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢

‡∏Å‡∏é:
1. ‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£"
3. ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤ (‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå, ‡∏´‡∏ô‡πâ‡∏≤) ‡πÄ‡∏™‡∏°‡∏≠

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á:
{context}

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}

‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á):
""")

        def format_docs(docs):
            formatted = []
            for doc in docs:
                source = doc.metadata.get("source", "unknown")
                page = doc.metadata.get("page", "?")
                formatted.append(
                    f"[üìÑ {Path(source).name} - ‡∏´‡∏ô‡πâ‡∏≤ {page + 1}]\n{doc.page_content}"
                )
            return "\n\n---\n\n".join(formatted)

        self.chain = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | prompt
            | self.llm
            | StrOutputParser()
        )

    def ask(self, question: str) -> str:
        """‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"""
        if not self.chain:
            raise RuntimeError("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤ load ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Å‡πà‡∏≠‡∏ô!")
        return self.chain.invoke(question)

# ===== ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô =====
def main():
    qa = PDFQASystem()

    # ‡πÇ‡∏´‡∏•‡∏î PDF
    qa.load_pdfs("./documents/")

    # ‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö
    print("\n" + "=" * 50)
    print("üìö PDF Q&A System ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")
    print("=" * 50)

    while True:
        question = input("\n‚ùì ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: ")
        if question.lower() in ["quit", "exit", "q"]:
            break

        print("\nüí° ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö...\n")
        answer = qa.ask(question)
        print(f"üìù ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:\n{answer}")

if __name__ == "__main__":
    main()
```

---

## Project 3: Research Agent (Multi-Agent)

### ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ

- ‚úÖ LangGraph multi-agent
- ‚úÖ Custom tools
- ‚úÖ State management
- ‚úÖ Sequential agent workflow

### Full Source Code

‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Python ‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

```python title="research_agent.py"
from typing import TypedDict, Annotated
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_openai import ChatOpenAI
from langchain_core.messages import AIMessage, HumanMessage
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.tools import tool
from datetime import datetime

# ===== State =====
class ResearchState(TypedDict):
    messages: Annotated[list, add_messages]
    topic: str
    research_data: str
    draft: str
    final_report: str
    current_phase: str

# ===== Tools =====
search = DuckDuckGoSearchRun()

@tool
def web_search(query: str) -> str:
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï"""
    return search.invoke(query)

# ===== Agents =====
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)

def research_agent(state: ResearchState) -> dict:
    """Agent 1: ‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏à‡∏±‡∏¢ ‚Äî ‡∏Ñ‡πâ‡∏ô‡∏Ñ‡∏ß‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    print("üîç [‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏à‡∏±‡∏¢] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏Ñ‡∏ß‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")

    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    search_results = web_search.invoke({"query": state["topic"]})

    response = llm.invoke([
        ("system", """‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏≠‡∏≤‡∏ß‡∏∏‡πÇ‡∏™
        - ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        - ‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        - ‡∏£‡∏∞‡∏ö‡∏∏‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""),
        ("human", f"""
        ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ß‡∏¥‡∏à‡∏±‡∏¢: {state['topic']}
        ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö: {search_results}

        ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        """),
    ])

    return {
        "messages": [response],
        "research_data": response.content,
        "current_phase": "research_complete",
    }

def writer_agent(state: ResearchState) -> dict:
    """Agent 2: ‡∏ô‡∏±‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô ‚Äî ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô"""
    print("‚úçÔ∏è [‡∏ô‡∏±‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô...")

    response = llm.invoke([
        ("system", """‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        - ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢
        - ‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô (‡∏ö‡∏ó‡∏ô‡∏≥, ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤, ‡∏™‡∏£‡∏∏‡∏õ)
        - ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏•‡∏∞‡∏™‡∏•‡∏ß‡∏¢"""),
        ("human", f"""
        ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {state['topic']}
        ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢:
        {state['research_data']}

        ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ
        """),
    ])

    return {
        "messages": [response],
        "draft": response.content,
        "current_phase": "writing_complete",
    }

def editor_agent(state: ResearchState) -> dict:
    """Agent 3: ‡∏ö‡∏£‡∏£‡∏ì‡∏≤‡∏ò‡∏¥‡∏Å‡∏≤‡∏£ ‚Äî ‡∏ï‡∏£‡∏ß‡∏à‡πÅ‡∏Å‡πâ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á"""
    print("üìù [‡∏ö‡∏£‡∏£‡∏ì‡∏≤‡∏ò‡∏¥‡∏Å‡∏≤‡∏£] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡πÅ‡∏Å‡πâ...")

    response = llm.invoke([
        ("system", """‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏£‡∏ì‡∏≤‡∏ò‡∏¥‡∏Å‡∏≤‡∏£‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
        - ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÉ‡∏´‡πâ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
        - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞
        - ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå 1-10"""),
        ("human", f"""
        ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏â‡∏ö‡∏±‡∏ö‡∏£‡πà‡∏≤‡∏á:
        {state['draft']}

        ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡πÅ‡∏Å‡πâ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡πâ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
        """),
    ])

    return {
        "messages": [response],
        "final_report": response.content,
        "current_phase": "editing_complete",
    }

# ===== Build Graph =====
graph = StateGraph(ResearchState)

# ‡πÄ‡∏û‡∏¥‡πà‡∏° nodes
graph.add_node("researcher", research_agent)
graph.add_node("writer", writer_agent)
graph.add_node("editor", editor_agent)

# ‡πÄ‡∏û‡∏¥‡πà‡∏° edges
graph.add_edge(START, "researcher")
graph.add_edge("researcher", "writer")
graph.add_edge("writer", "editor")
graph.add_edge("editor", END)

# Compile
app = graph.compile()

# ===== ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô =====
def research(topic: str) -> str:
    """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢"""
    print(f"\n{'='*50}")
    print(f"üî¨ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {topic}")
    print(f"{'='*50}\n")

    result = app.invoke({
        "messages": [HumanMessage(content=f"‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á: {topic}")],
        "topic": topic,
        "research_data": "",
        "draft": "",
        "final_report": "",
        "current_phase": "start",
    })

    print(f"\n{'='*50}")
    print("‚úÖ ‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!")
    print(f"{'='*50}\n")

    return result["final_report"]

# Main
if __name__ == "__main__":
    topic = input("üî¨ ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢: ")
    report = research(topic)

    print("\nüìã ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå:")
    print("=" * 50)
    print(report)

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
    filename = f"report_{datetime.now():%Y%m%d_%H%M}.md"
    with open(filename, "w", encoding="utf-8") as f:
        f.write(f"# {topic}\n\n{report}")
    print(f"\nüíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô: {filename}")
```

---

## ‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ

<CardGrid>
  <Card title="üìò ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô" icon="open-book">
    LLMs, Chat Models, Prompt Templates, Output Parsers
  </Card>
  <Card title="üìó Core" icon="puzzle">
    LCEL Chains, Memory, Streaming, Error Handling
  </Card>
  <Card title="üìï Advanced" icon="rocket">
    RAG, Agents, Tools, LangGraph Multi-Agent
  </Card>
  <Card title="üöÄ Production" icon="setting">
    LangServe, Docker, LangSmith, Testing, Cost Optimization
  </Card>
</CardGrid>

---

## ‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°

| ‡πÅ‡∏´‡∏•‡πà‡∏á            | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                         | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢               |
| ---------------- | ----------------------------------------------------------------------------- | ---------------------- |
| LangChain Docs   | [python.langchain.com](https://python.langchain.com/)                         | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£  |
| LangGraph Docs   | [langchain-ai.github.io/langgraph](https://langchain-ai.github.io/langgraph/) | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ LangGraph       |
| LangSmith        | [smith.langchain.com](https://smith.langchain.com/)                           | Monitoring & Debugging |
| LangChain GitHub | [github.com/langchain-ai](https://github.com/langchain-ai)                    | Source code & issues   |
| LangChain Blog   | [blog.langchain.dev](https://blog.langchain.dev/)                             | ‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞ tutorials   |

---

<Aside type="tip" title="üéâ ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏î‡πâ‡∏ß‡∏¢!">
  ‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏à‡∏ö‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠ **LangChain ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå** ‡πÅ‡∏•‡πâ‡∏ß!
  ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á AI Application ‡∏£‡∏∞‡∏î‡∏±‡∏ö Production ‡πÑ‡∏î‡πâ‡πÅ‡∏•‡πâ‡∏ß
  ‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏ô‡∏∏‡∏Å‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏¥‡πà‡∏á‡πÉ‡∏´‡∏°‡πà‡πÜ! üöÄ
</Aside>
