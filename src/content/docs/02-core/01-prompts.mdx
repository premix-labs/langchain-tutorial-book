---
title: "‡∏ö‡∏ó‡∏ó‡∏µ‡πà 4: Prompt Templates ‡πÅ‡∏•‡∏∞ Output Parsers"
description: "‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å LLM ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á"
sidebar:
  order: 4
---

import {
  Aside,
  Tabs,
  TabItem,
  Steps,
  Card,
  CardGrid,
} from "@astrojs/starlight/components";

## ‡∏ó‡∏≥‡πÑ‡∏° Prompt Engineering ‡∏ñ‡∏∂‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç?

Prompt ‡∏Ñ‡∏∑‡∏≠ **‡∏™‡∏¥‡πà‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß** ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏Å‡∏±‡∏ö LLM ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô Prompt ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ ‡πÅ‡∏•‡∏∞ Prompt ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÅ‡∏¢‡πà

```
Prompt ‡∏î‡∏µ  ‚Üí ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏î‡∏µ  ‚úÖ
Prompt ‡πÅ‡∏¢‡πà ‚Üí ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏¢‡πà ‚ùå
```

---

## ChatPromptTemplate

### Basic Template

‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Python ‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

```python
from langchain_core.prompts import ChatPromptTemplate

# ‡∏™‡∏£‡πâ‡∏≤‡∏á template ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
prompt = ChatPromptTemplate.from_messages([
    ("system", "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô {expertise}. ‡∏ï‡∏≠‡∏ö‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô"),
    ("human", "{question}"),
])

# ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
result = prompt.invoke({
    "expertise": "Python Programming",
    "question": "Lambda function ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?"
})
print(result)
```

### Template ‡∏Å‡∏±‡∏ö Multiple Variables

‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Python ‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

```python
prompt = ChatPromptTemplate.from_messages([
    ("system", """‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
    - ‡πÅ‡∏õ‡∏•‡∏à‡∏≤‡∏Å {source_lang} ‡πÄ‡∏õ‡πá‡∏ô {target_lang}
    - ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ô‡πâ‡∏≥‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏î‡∏¥‡∏°
    - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡πÉ‡∏ô‡∏ß‡∏á‡πÄ‡∏•‡πá‡∏ö"""),
    ("human", "‡πÅ‡∏õ‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ: {text}"),
])

chain = prompt | llm | StrOutputParser()
result = chain.invoke({
    "source_lang": "‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©",
    "target_lang": "‡πÑ‡∏ó‡∏¢",
    "text": "Machine learning is a subset of artificial intelligence."
})
print(result)
# Machine Learning (‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á) ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏¢‡πà‡∏≠‡∏¢‡∏Ç‡∏≠‡∏á
# ‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå (Artificial Intelligence)
```

---

## Few-Shot Prompting

### ‡πÉ‡∏™‡πà‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à pattern

‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Python ‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

```python
from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate

# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö few-shot
examples = [
    {"input": "‡∏™‡∏ö‡∏≤‡∏¢‡∏î‡∏µ‡πÑ‡∏´‡∏°", "output": "How are you?"},
    {"input": "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏°‡∏≤‡∏Å", "output": "Thank you very much"},
    {"input": "‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏£", "output": "You're welcome / No problem"},
]

# ‡∏™‡∏£‡πâ‡∏≤‡∏á example prompt
example_prompt = ChatPromptTemplate.from_messages([
    ("human", "{input}"),
    ("ai", "{output}"),
])

# ‡∏™‡∏£‡πâ‡∏≤‡∏á few-shot prompt
few_shot_prompt = FewShotChatMessagePromptTemplate(
    example_prompt=example_prompt,
    examples=examples,
)

# ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ö prompt ‡∏´‡∏•‡∏±‡∏Å
final_prompt = ChatPromptTemplate.from_messages([
    ("system", "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡πÅ‡∏õ‡∏•‡πÑ‡∏ó‡∏¢-‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡πÅ‡∏õ‡∏•‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥"),
    few_shot_prompt,
    ("human", "{input}"),
])

chain = final_prompt | llm | StrOutputParser()
result = chain.invoke({"input": "‡∏Å‡∏¥‡∏ô‡∏Ç‡πâ‡∏≤‡∏ß‡∏¢‡∏±‡∏á"})
print(result)  # "Have you eaten yet?"
```

---

## Dynamic Prompt Selection

### ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å prompt ‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç

‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Python ‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

```python
from langchain_core.prompts import ChatPromptTemplate

# ‡∏™‡∏£‡πâ‡∏≤‡∏á prompts ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏á‡∏≤‡∏ô
prompts = {
    "summarize": ChatPromptTemplate.from_messages([
        ("system", "‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ"),
        ("human", "{text}"),
    ]),
    "translate": ChatPromptTemplate.from_messages([
        ("system", "‡πÅ‡∏õ‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô {target_lang}"),
        ("human", "{text}"),
    ]),
    "analyze": ChatPromptTemplate.from_messages([
        ("system", "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô: Positive/Negative/Neutral ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•"),
        ("human", "{text}"),
    ]),
}

def process_text(task: str, **kwargs):
    prompt = prompts[task]
    chain = prompt | llm | StrOutputParser()
    return chain.invoke(kwargs)

# ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
result = process_text("summarize", text="‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÜ ...")
result = process_text("translate", text="Hello", target_lang="‡πÑ‡∏ó‡∏¢")
result = process_text("analyze", text="‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏£‡πâ‡∏≤‡∏ô‡∏ô‡∏µ‡πâ‡∏≠‡∏£‡πà‡∏≠‡∏¢‡∏°‡∏≤‡∏Å!")
```

---

## Output Parsers ‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î

### 1. StrOutputParser ‚Äî ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô String

‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Python ‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

```python
from langchain_core.output_parsers import StrOutputParser

parser = StrOutputParser()
chain = prompt | llm | parser

# ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô string ‡πÄ‡∏™‡∏°‡∏≠
result = chain.invoke({"question": "Python ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?"})
type(result)  # str
```

### 2. PydanticOutputParser ‚Äî ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Object

‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Python ‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

```python
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field

class BookInfo(BaseModel):
    title: str = Field(description="‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠")
    author: str = Field(description="‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÅ‡∏ï‡πà‡∏á")
    genre: str = Field(description="‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó")
    year: int = Field(description="‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏û‡∏¥‡∏°‡∏û‡πå")
    summary: str = Field(description="‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏™‡∏±‡πâ‡∏ô‡πÜ")

parser = PydanticOutputParser(pydantic_object=BookInfo)

prompt = ChatPromptTemplate.from_messages([
    ("system", "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON\n{format_instructions}"),
    ("human", "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠: {book_name}"),
])

chain = prompt.partial(
    format_instructions=parser.get_format_instructions()
) | llm | parser

result = chain.invoke({"book_name": "Harry Potter and the Philosopher's Stone"})
print(f"‡∏ä‡∏∑‡πà‡∏≠: {result.title}")
print(f"‡∏ú‡∏π‡πâ‡πÅ‡∏ï‡πà‡∏á: {result.author}")
print(f"‡∏õ‡∏µ: {result.year}")
```

### 3. CommaSeparatedListOutputParser ‚Äî ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô List

‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Python ‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

```python
from langchain_core.output_parsers import CommaSeparatedListOutputParser

parser = CommaSeparatedListOutputParser()

prompt = ChatPromptTemplate.from_template(
    "‡∏ö‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠ {category} ‡∏°‡∏≤ 5 ‡∏≠‡∏¢‡πà‡∏≤‡∏á ‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏à‡∏∏‡∏•‡∏†‡∏≤‡∏Ñ\n{format_instructions}"
)

chain = prompt.partial(
    format_instructions=parser.get_format_instructions()
) | llm | parser

result = chain.invoke({"category": "‡∏ú‡∏•‡πÑ‡∏°‡πâ‡πÑ‡∏ó‡∏¢"})
print(result)
# ['‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á', '‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô', '‡∏°‡∏±‡∏á‡∏Ñ‡∏∏‡∏î', '‡∏•‡∏≥‡πÑ‡∏¢', '‡πÄ‡∏á‡∏≤‡∏∞']
```

---

## Structured Output (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‚≠ê)

‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö structured data ‚Äî ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Output Parser:

```python
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI

class TaskAnalysis(BaseModel):
    """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥"""
    task_name: str = Field(description="‡∏ä‡∏∑‡πà‡∏≠‡∏á‡∏≤‡∏ô")
    priority: str = Field(description="‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: high/medium/low")
    estimated_hours: float = Field(description="‡πÄ‡∏ß‡∏•‡∏≤‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì (‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á)")
    subtasks: list[str] = Field(description="‡∏á‡∏≤‡∏ô‡∏¢‡πà‡∏≠‡∏¢")
    tools_needed: list[str] = Field(description="‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ")

llm = ChatOpenAI(model="gpt-4o-mini")
structured_llm = llm.with_structured_output(TaskAnalysis)

result = structured_llm.invoke(
    "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏á‡∏≤‡∏ô: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡πá‡∏ö e-commerce ‡∏î‡πâ‡∏ß‡∏¢ Next.js"
)

print(f"üìã ‡∏á‡∏≤‡∏ô: {result.task_name}")
print(f"üî• ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: {result.priority}")
print(f"‚è±Ô∏è ‡πÄ‡∏ß‡∏•‡∏≤: {result.estimated_hours} ‡∏ä‡∏°.")
print(f"üìù ‡∏á‡∏≤‡∏ô‡∏¢‡πà‡∏≠‡∏¢:")
for st in result.subtasks:
    print(f"  - {st}")
```

<Aside type="tip">
  **with_structured_output()** ‡πÉ‡∏ä‡πâ **function calling** ‡∏Ç‡∏≠‡∏á LLM ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô
  ‡∏à‡∏∂‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£ parse JSON ‡∏à‡∏≤‡∏Å text ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤
</Aside>

---

## ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ Prompt Engineering

### 1. Role Playing

‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Python ‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

```python
prompt = ChatPromptTemplate.from_messages([
    ("system", """‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô Senior Software Architect ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå 15 ‡∏õ‡∏µ
    - ‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤ scalability, maintainability, ‡πÅ‡∏•‡∏∞ security
    - ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
    - ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢"""),
    ("human", "{question}"),
])
```

### 2. Chain of Thought (CoT)

‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Python ‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

```python
prompt = ChatPromptTemplate.from_messages([
    ("system", """‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢:
    1. ‡∏Ñ‡∏¥‡∏î‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô (step by step)
    2. ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏¥‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô
    3. ‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢"""),
    ("human", "{question}"),
])
```

### 3. Output Format Specification

‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡πÅ‡∏û‡∏ï‡πÄ‡∏ó‡∏¥‡∏£‡πå‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏•‡πà‡∏°

````python
prompt = ChatPromptTemplate.from_messages([
    ("system", """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏Ñ‡πâ‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö:

    ## ‡∏™‡∏£‡∏∏‡∏õ
    [‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏±‡πâ‡∏ô‡πÜ]

    ## ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö
    - [‡∏õ‡∏±‡∏ç‡∏´‡∏≤ 1]
    - [‡∏õ‡∏±‡∏ç‡∏´‡∏≤ 2]

    ## ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç
    ```python
    [‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß]
    ```

    ## ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô
    [‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô 1-10] ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•"""),
    ("human", "Review ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ô‡∏µ‡πâ:\n```python\n{code}\n```"),
])
````

---

## ‡∏™‡∏£‡∏∏‡∏õ

| Component                  | ‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠                          | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á               |
| -------------------------- | --------------------------------- | ---------------------- |
| **ChatPromptTemplate**     | ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á             | Template ‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£     |
| **FewShotPrompt**          | ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ AI ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á | ‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤, ‡∏à‡∏±‡∏î format    |
| **StrOutputParser**        | ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ text output               | ‡∏™‡∏£‡∏∏‡∏õ, ‡πÅ‡∏õ‡∏•, ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°    |
| **PydanticOutputParser**   | ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ structured object         | ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå   |
| **with_structured_output** | ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ structured data (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥!)  | ‡∏ó‡∏∏‡∏Å‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ JSON |

---

:::note[‡∏ï‡πà‡∏≠‡πÑ‡∏õ üîó]
‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à Prompt Templates ‡πÅ‡∏•‡πâ‡∏ß ‡πÑ‡∏õ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£ **[‡∏™‡∏£‡πâ‡∏≤‡∏á Chains ‡∏î‡πâ‡∏ß‡∏¢ LCEL](/02-core/02-chains-lcel/)** ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á LangChain!
:::
